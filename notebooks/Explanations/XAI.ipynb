{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7234ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "import collections\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfb5f1-79ed-40bd-8db1-27180c6b16b5",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440803b0-2f0b-45a9-96ab-68da77797eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "here_path = Path().resolve()\n",
    "repo_path = here_path.parents[1]\n",
    "sys.path.append(str(repo_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce7334-8287-4b8a-b6a0-3d952d91d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.utils import verifyDir, verifyFile, verifyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8f938-3cc7-4a5a-9033-96653a0c8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afacf91-ea4e-4c10-af2e-ecd6d8576bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.config import Config\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "np.random.seed(cfg.RANDOM_STATE)\n",
    "cfg.DATA_PATH, cfg.MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76f508-8c42-4e66-bcc5-8205d149a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "QSCORE_PATH=f\"{cfg.DATA_PATH}pp1/Qscores/\"\n",
    "IMAGES_PATH = f\"{cfg.DATA_PATH}pp1/images/\"\n",
    "MODEL_PATH = f\"{cfg.MODEL_PATH}pp1/{cfg.YEAR_STUDIED}/cnn/\"\n",
    "EXPLAIN_PATH = f\"{cfg.MODEL_PATH}pp1/{cfg.YEAR_STUDIED}/explanations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbeedf-241e-4cda-b335-c31190ad9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "verifyDir(MODEL_PATH)\n",
    "verifyDir(EXPLAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db9ce3-42b7-4957-b395-c31c4540feb4",
   "metadata": {},
   "source": [
    "### Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cd3c8-ec42-4f77-8dff-b7c55db6b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_type = torch.float32 if device.type == \"cuda\" else torch.float16\n",
    "device, torch_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74de26-e62d-472c-8cfe-04341f147d07",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e45bd-3bcb-4540-b652-6e2c47a6552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1 if \"reg\" in cfg.ML_TASK else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd546c-52f8-4169-ad87-5b54b88d49c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data_df = pd.read_csv(f\"{QSCORE_PATH}scores.csv\", sep=\";\", low_memory=False)\n",
    "data_df[\"image_path\"] = f\"{IMAGES_PATH}{cfg.YEAR_STUDIED}/\" + data_df[\"image_path\"]\n",
    "data_df[\"image_id\"] = data_df[\"image_id\"].apply(str)\n",
    "data_df.sort_values(by=[cfg.PERCEPTION_METRIC], ascending=False, inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f4d53-011a-4f2e-b958-5cdea2d8c112",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07f69-2f22-4139-82e3-32b1f6f1f843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from py.models.classification.cnn.vgg import VGG16\n",
    "\n",
    "model = VGG16(num_classes=2, use_mlp=True)\n",
    "model.load_state_dict(torch.load(f\"{MODEL_PATH}{cfg.MODEL_FEATURE_NAME}_best_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ba31e-6e3d-417c-a811-b6be01f6beea",
   "metadata": {},
   "source": [
    "#### Image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab4140-92ee-4fff-abd4-2e3a8e6f395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.models.datasets.transformations import ImageTransforms\n",
    "\n",
    "transforms_list = ImageTransforms().get(model_name=cfg.MODEL_FEATURE_NAME)\n",
    "transforms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8182c94-951c-4814-b0ff-88c46e8658ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "original_image = Image.open(data_df[\"image_path\"].tolist()[0]).convert(\"RGB\")\n",
    "original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3fc10-ff8c-4e37-a466-bd7c316b22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 1 # not safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b42811-6a3b-4bb4-b0fe-b3ceba48e939",
   "metadata": {},
   "source": [
    "### GradCAM (Gradient-weighted Class Activation Mapping)\n",
    "\n",
    "- **What it does**: Shows which parts of the image the model is \"looking at\" when making predictions\n",
    "- **How it works**: Uses gradients flowing into the last convolutional layer to highlight important regions\n",
    "- **Speed**: Very fast (~0.1 seconds per image)\n",
    "- **Best for**: Understanding spatial attention and localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad698405-f28e-440d-a974-23cf5e92ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.models.explainers import GradCAM\n",
    "\n",
    "gradcam = GradCAM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8e845-0f28-429a-901e-f7c766c98906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate explanation (input_tensor: 1x3x224x224, original_image: HxWx3)\n",
    "cam_heatmap, gradcam_predicted_class = gradcam.generate_cam(\n",
    "                                            original_image,\n",
    "                                            transforms_list=transforms_list[\"val\"],\n",
    "                                            target_class=target_class  # None = use predicted class, or specify a class index\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd2f39c-680a-4445-97fa-72c26b56ffcf",
   "metadata": {},
   "source": [
    "#### GradCAM Interpretation\n",
    "\n",
    "- **Red/Yellow regions**: Areas the model focuses on most\n",
    "- **Blue regions**: Areas the model ignores\n",
    "- **Heatmap**: Shows spatial importance across the image\n",
    "- **Good for**: \"Where is the model looking?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70218a-20b0-4f4d-886a-c163218133f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate explanation (input_tensor: 1x3x224x224, original_image: HxWx3)\n",
    "gradcam_viz, cam_resized = gradcam.visualize(\n",
    "                    original_image,\n",
    "                    cam_heatmap,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd3b36-9972-4cd6-b3f8-291ab50c4910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(gradcam_viz)\n",
    "plt.title(f'Predicted: Class {gradcam_predicted_class}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31094c8-0cd2-492e-9f4e-e2ca48867800",
   "metadata": {},
   "source": [
    "### LIME (Local Interpretable Model-agnostic Explanations)\n",
    "\n",
    "- **What it does**: Highlights which image regions contribute most to the prediction\n",
    "- **How it works**: Perturbs the image and sees how predictions change\n",
    "- **Speed**: Slower (~30-60 seconds per image with 1000 samples)\n",
    "- **Best for**: Understanding feature importance in a human-interpretable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bc8e9-d21c-4037-833c-44e5cafc8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.models.explainers import ImageLIME\n",
    "\n",
    "# Create LIME explainer\n",
    "lime_explainer = ImageLIME(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6456ce-0a88-4558-b0b5-deaabd01f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "explanation, lime_predicted_class = lime_explainer.explain(\n",
    "                                        original_image,\n",
    "                                        transforms_list[\"val\"],\n",
    "                                        target_class=target_class,\n",
    "                                        num_samples=1000,  # More samples = better but slower\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ce2a7-d279-44cb-902f-c14472fd1f93",
   "metadata": {},
   "source": [
    "#### LIME Interpretation\n",
    "\n",
    "- **Green regions**: Features that increase the class probability\n",
    "- **Red regions**: Features that decrease the class probability\n",
    "- **Superpixels**: Image is divided into interpretable segments\n",
    "- **Good for**: \"Which features matter for this prediction?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823df222-67ff-4b40-9fbe-63baff148c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_viz = lime_explainer.visualize(original_image, \n",
    "                                   explanation,\n",
    "                                   target_class=lime_predicted_class,\n",
    "                                   num_features=10,      # Show top 10 superpixels\n",
    "                                   positive_only=False   # Show both positive and negative contributions\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c41265-e754-41c9-b5a4-448d87dc07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lime_viz)\n",
    "plt.title(f'LIME: Class {lime_predicted_class}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32b416-0420-4509-a2a0-7a668ee456df",
   "metadata": {},
   "source": [
    "#### Visualize both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee996c-b6a3-498a-8631-533a6a9d8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# GradCAM\n",
    "axes[1].imshow(gradcam_viz)\n",
    "axes[1].set_title(f'GradCAM: class {gradcam_predicted_class}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# LIME\n",
    "axes[2].imshow(lime_viz)\n",
    "axes[2].set_title(f'LIME: class {lime_predicted_class}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
